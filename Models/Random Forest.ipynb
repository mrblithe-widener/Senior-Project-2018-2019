{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants (Feel free to tweek these and observe different outcomes)\n",
    "ENABLE_DISTRICT_SPLIT = False #This will ensure that schools in the same district are groupped into either trianing, validation or test. Without it they may stradle this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Loading the data with pandas\n",
    "math = pd.read_csv(\"../Data/math.csv\")\n",
    "read = pd.read_csv(\"../Data/read.csv\")\n",
    "business = pd.read_csv(\"../Data/BUSSINES.csv\")\n",
    "geo = pd.read_csv(\"../Data/geo.csv\", low_memory=False)\n",
    "funding = pd.read_csv(\"../Data/FUNDING.csv\")\n",
    "income = pd.read_csv(\"../Data/income.csv\")\n",
    "teachers = pd.read_csv(\"../Data/Teacher Ratios.csv\")\n",
    "title1 = pd.read_csv(\"../Data/title1.csv\")\n",
    "#Set indexs\n",
    "math = math.set_index(\"math_ncessch\")\n",
    "read = read.set_index(\"read_ncessch\")\n",
    "business = business.set_index(\"zip_code\")\n",
    "funding[\"ncesid\"] = pd.to_numeric(funding[\"ncesid\"], errors=\"coerce\")\n",
    "funding = funding.set_index(\"ncesid\")\n",
    "geo = geo.set_index(\"ncessch\")\n",
    "income = income.set_index(\"zipcode\")\n",
    "teachers[\"ncessch\"] = teachers[\"ncessch\"].astype(np.int64)\n",
    "teachers = teachers.set_index(\"ncessch\")\n",
    "title1[\"ncessch\"] = title1[\"ncessch\"].astype(np.int64)\n",
    "title1 = title1.set_index(\"ncessch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yes, under Community Eligibility Option (CEO)',\n",
       " 'Yes, under Provision 2',\n",
       " 'Yes, participating without using any Provision or the CEO',\n",
       " 'No',\n",
       " 'MISSING',\n",
       " 'Yes, under Provision 1']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(title1['ntnl_school_lunch_program_status']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix title1 data\n",
    "title1 = title1[title1['title_i_status'] != 'M']\n",
    "title1 = title1[title1['title_i_status'] != '-9']\n",
    "title1 = title1[title1['title_i_eligibility'] != 'Missing']\n",
    "title1 = title1[title1['title_i_eligibility'] != '-9']\n",
    "title1 = title1[title1['ntnl_school_lunch_program_status'] != 'MISSING']\n",
    "title1 = title1[title1['ntnl_school_lunch_program_status'] != '-9']\n",
    "title1 = title1[title1['school_wide_title_i_eligibility'] != 'Missing']\n",
    "title1 = title1[title1['school_wide_title_i_eligibility'] != '-9']\n",
    "title1['ntnl_school_lunch_program_status_Yes'] = title1['ntnl_school_lunch_program_status'].apply(lambda x: 'Yes' in x)\n",
    "title1 = pd.concat([title1.drop('title_i_eligibility',1),pd.get_dummies(title1[\"title_i_eligibility\"], prefix='title_1_eligbility_')], axis=1)\n",
    "title1 = pd.concat([title1.drop('school_wide_title_i_eligibility',1),pd.get_dummies(title1[\"school_wide_title_i_eligibility\"], prefix='school_wide_title_i_eligibility')], axis=1)\n",
    "title1 = pd.concat([title1.drop('ntnl_school_lunch_program_status',1),pd.get_dummies(title1[\"ntnl_school_lunch_program_status\"], prefix='ntnl_school_lunch_program_status')], axis=1)\n",
    "\n",
    "#Fix teachers\n",
    "teachers= teachers[teachers['num_full_time'] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combines the datasets together. This is similar to SQL's join statements but uses Pandas\n",
    "combined = math[['math_leaid','math_all_grades_numvalid','math_all_grades_pctprof_low','math_all_grades_pctprof_high']].join([read[['read_all_grades_numvalid','read_all_grades_pctprof_low','read_all_grades_pctprof_high']],geo[['zip','locale','lat','lon']]], how=\"inner\")\n",
    "combined = combined.join(business[['num_establishments',\"num_paid_employees\", \"first_quarter_payroll\", \"annual_payroll\"]], how=\"inner\", on=\"zip\")\n",
    "combined = combined.join(funding.drop([\"idcensus\",\"name\",\"conum\",\"csa\",\"cbsa\",\"enroll\"],1), how=\"inner\", on=\"math_leaid\")\n",
    "combined = combined.join(income.drop([\"statefips\",'state'], 1), how=\"inner\", on=\"zip\")\n",
    "combined = combined.join(teachers[\"num_full_time\"], how=\"inner\")\n",
    "combined = combined.join(title1[[\"title_i_status\",'ntnl_school_lunch_program_status_Yes', 'title_1_eligbility__No',\n",
    "       'title_1_eligbility__Not Applicable', 'title_1_eligbility__Yes',\n",
    "       'school_wide_title_i_eligibility_No',\n",
    "       'school_wide_title_i_eligibility_Not Applicable',\n",
    "       'school_wide_title_i_eligibility_Yes',\n",
    "       'ntnl_school_lunch_program_status_No',\n",
    "       'ntnl_school_lunch_program_status_Yes, participating without using any Provision or the CEO',\n",
    "       'ntnl_school_lunch_program_status_Yes, under Community Eligibility Option (CEO)',\n",
    "       'ntnl_school_lunch_program_status_Yes, under Provision 1',\n",
    "       'ntnl_school_lunch_program_status_Yes, under Provision 2']], how=\"inner\")\n",
    "combined = combined.drop(['zip','num_paid_employees',\"first_quarter_payroll\", \"annual_payroll\"],1)\n",
    "combined = combined[combined['math_all_grades_pctprof_low'] >=0]\n",
    "combined = combined[combined['read_all_grades_pctprof_low'] >=0]\n",
    "combined['math_full_time'] = combined['math_all_grades_numvalid']/combined['num_full_time']\n",
    "combined['read_full_time'] = combined['read_all_grades_numvalid']/combined['num_full_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxBySchoolDistrict(df):\n",
    "    entryGroups = []\n",
    "    groups = df.groupby('math_leaid')\n",
    "    for name, entry in groups:\n",
    "        entryGroups.append(entry)\n",
    "    return entryGroups\n",
    "def unbox(entryGroups):\n",
    "    df = pd.DataFrame()\n",
    "    return pd.concat(entryGroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping by school districts\n",
    "The above code groups the data by school district to ensure that each school in a school district is either in the training, test or validation data. If this is not enabled then one school from the district may be in the training, another in the test group and one in the validation group. This is important because some of the data relies on school districts rather than individual schools this ensures that the models are learning the trends not just memorizing what happened at other schools. Untimatly, it is up to the user to determine the importance of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-5617a900a223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmath_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"math_all_grades_pctprof_low\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"math_all_grades_pctprof_high\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"read_all_grades_pctprof_low\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"read_all_grades_pctprof_high\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmath_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmath_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath_y_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplitValuesMath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmath_X_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath_y_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplitValuesMath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmath_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplitValuesMath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-5617a900a223>\u001b[0m in \u001b[0;36mSplitValuesMath\u001b[0;34m(math)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmath_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_train_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mSplitValuesMath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmath_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'math_all_grades_pctprof_low'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'math_all_grades_pctprof_high'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmath_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"math_all_grades_pctprof_low\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"math_all_grades_pctprof_high\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"read_all_grades_pctprof_low\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"read_all_grades_pctprof_high\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-3f131b384edc>\u001b[0m in \u001b[0;36munbox\u001b[0;34m(entryGroups)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentryGroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentryGroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    223\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    239\u001b[0m             raise TypeError('first argument must be an iterable of pandas '\n\u001b[1;32m    240\u001b[0m                             \u001b[0;34m'objects, you passed an object of type '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                             '\"{name}\"'.format(name=type(objs).__name__))\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjoin\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'outer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\""
     ]
    }
   ],
   "source": [
    "if ENABLE_DISTRICT_SPLIT:\n",
    "    math_train_val, math_test,  = train_test_split(boxBySchoolDistrict(combined), test_size = .2, train_size = .8, random_state =42 )\n",
    "else:\n",
    "    math_train_val, math_test,  = train_test_split(combined, test_size = .2, train_size = .8, random_state =42 )\n",
    "math_train, math_val = train_test_split(math_train_val, test_size = .3, train_size = .7, random_state =42 )\n",
    "def SplitValuesMath(math):\n",
    "    math = unbox(math)\n",
    "    math_y = (math['math_all_grades_pctprof_low']+math['math_all_grades_pctprof_high'])/2\n",
    "    math_x = math.drop([\"math_all_grades_pctprof_low\",\"math_all_grades_pctprof_high\",\"read_all_grades_pctprof_low\",\"read_all_grades_pctprof_high\"],1)\n",
    "    return math_x, math_y\n",
    "math_X_train, math_y_train = SplitValuesMath(math_train)\n",
    "math_X_val, math_y_val = SplitValuesMath(math_val)\n",
    "math_X_test, math_y_test = SplitValuesMath(math_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#depth = 0\n",
    "#max_score = 0\n",
    "#for i in range(1,20):\n",
    "#    print(\"running with max depth \", i)\n",
    "#    rfr = RandomForestRegressor(n_estimators=100, max_depth=i, random_state=42)\n",
    "#    trained = rfr.fit(math_X_train, math_y_train)\n",
    "#    score = rfr.score(math_X_val, math_y_val)\n",
    "#    print(\"validation score\", score)\n",
    "#    if score > max_score:\n",
    "#        depth = i\n",
    "#        max_score = score\n",
    "\n",
    "#Optimal at 19 max depth\n",
    "rfr = RandomForestRegressor(n_estimators=100, max_depth=19, random_state=42)\n",
    "trained = rfr.fit(math_X_train, math_y_train)\n",
    "print(rfr.score(math_X_test, math_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDelta(x_test, y_test,estimator):\n",
    "    predictions = np.array(estimator.predict(x_test))\n",
    "    return np.mean(np.absolute(predictions - y_test))\n",
    "calculateDelta(math_X_test, math_y_test, rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame({'scores':rfr.feature_importances_, 'names':math_X_train.columns})\n",
    "features.sort_values(by='scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
