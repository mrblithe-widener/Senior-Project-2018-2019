# -*- coding: utf-8 -*-
"""Neural Network For Django.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14u7vORJiScdeGxtE3y1_I66sJx9u5_bf
"""

#Imports
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import r2_score, accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.utils import plot_model
from tensorflow.keras.regularizers import l2
from tensorflow.keras.regularizers import l1
from tensorflow.keras import optimizers
import tensorflow as tf
import math
import random
import os
from keras.models import load_model
from joblib import dump, load

RANDOM_STATE = 10

from numpy.random import seed
seed(RANDOM_STATE)
from tensorflow import set_random_seed
set_random_seed(RANDOM_STATE)

print("Starting to Load Data")
#Loading the data with pandas
math_scores = pd.read_csv("../DB_Export/math.csv")
read = pd.read_csv("../DB_Export/read.csv")
business = pd.read_csv("../DB_Export/BUSSINES.csv")
geo = pd.read_csv("../DB_Export/geo.csv", low_memory=False)
funding = pd.read_csv("../DB_Export/FUNDING.csv")
income = pd.read_csv("../DB_Export/income.csv")
teachers = pd.read_csv("../DB_Export/Teacher Ratios.csv")
title1 = pd.read_csv("../DB_Export/title1.csv")
print("Loaded Data")
#Set indexs
math_scores = math_scores.set_index("math_ncessch")
read = read.set_index("read_ncessch")
business = business.set_index("zip_code")
funding["ncesid"] = pd.to_numeric(funding["ncesid"], errors="coerce")
funding = funding.set_index("ncesid")
geo = geo.set_index("ncessch")
income = income.set_index("zipcode")
teachers["ncessch"] = teachers["ncessch"].astype(np.int64)
teachers = teachers.set_index("ncessch")
title1["ncessch"] = title1["ncessch"].astype(np.int64)
title1 = title1.set_index("ncessch")

#Fix title1 data
title1 = title1[title1['title_i_status'] != 'M']
title1 = title1[title1['title_i_status'] != '-9']
title1 = title1[title1['title_i_eligibility'] != 'Missing']
title1 = title1[title1['title_i_eligibility'] != '-9']
title1 = title1[title1['ntnl_school_lunch_program_status'] != 'MISSING']
title1 = title1[title1['ntnl_school_lunch_program_status'] != '-9']
title1 = title1[title1['school_wide_title_i_eligibility'] != 'Missing']
title1 = title1[title1['school_wide_title_i_eligibility'] != '-9']
title1['ntnl_school_lunch_program_status_Yes'] = title1['ntnl_school_lunch_program_status'].apply(lambda x: 'Yes' in x)
title1 = pd.concat([title1.drop('title_i_eligibility',1),pd.get_dummies(title1["title_i_eligibility"], prefix='title_1_eligbility_')], axis=1)
title1 = pd.concat([title1.drop('school_wide_title_i_eligibility',1),pd.get_dummies(title1["school_wide_title_i_eligibility"], prefix='school_wide_title_i_eligibility')], axis=1)
title1 = pd.concat([title1.drop('ntnl_school_lunch_program_status',1),pd.get_dummies(title1["ntnl_school_lunch_program_status"], prefix='ntnl_school_lunch_program_status')], axis=1)

mathStatesPairs = {'HAWAII':0,
    'IOWA':1,
    'RHODE ISLAND':2,
    'OREGON':3,
    'OKLAHOMA':4,
    'OHIO':5,
    'MISSOURI':6,
    'NEW YORK':7,
    'WEST VIRGINIA':8,
    'VIRGINIA':9,
    'MASSACHUSETTS':10,
    'TEXAS':11,
    'ALABAMA':12,
    'SOUTH DAKOTA':13,
    'ARIZONA':14,
    'NEW HAMPSHIRE':15,
    'MICHIGAN':16,
    'MISSISSIPPI':17,
    'DELAWARE':18,
    'MONTANA':19,
    'WYOMING':20,
    'INDIANA':21,
    'SOUTH CAROLINA':22,
    'WISCONSIN':23,
    'VIRGIN ISLANDS':24,
    'NEW MEXICO':25,
    'KENTUCKY':26,
    'KANSAS':27,
    'VERMONT':28,
    'WASHINGTON':29,
    'DISTRICT OF COLUMBIA':30,
    'NORTH DAKOTA':31,
    'NORTH CAROLINA':32,
    'NEBRASKA':33,
    'MARYLAND':34,
    'MAINE':35,
    'MINNESOTA':36,
    'BUREAU OF INDIAN AFFAIRS':37,
    'ILLINOIS':38,
    'FLORIDA':39,
    'NEVADA':40,
    'NEW JERSEY':41,
    'IDAHO':42,
    'CALIFORNIA':43,
    'ALASKA':44,
    'COLORADO':45,
    'CONNECTICUT':46,
    'UTAH':47,
    'ARKANSAS':48,
    'GEORGIA':49,
    'PENNSYLVANIA':50,
    'LOUISIANA':51,
    'PUERTO RICO':52,
    'TENNESSEE':53}

#Fix teachers
teachers= teachers[teachers['num_full_time'] >0]

#Combines the datasets together. This is similar to SQL's join statements but uses Pandas
combined = math_scores[['math_leaid','math_stnam','math_all_grades_numvalid','math_all_grades_pctprof_low','math_all_grades_pctprof_high']].join([read[['read_all_grades_numvalid','read_all_grades_pctprof_low','read_all_grades_pctprof_high']],geo[['zip','locale','lat','lon']]], how="inner")
#combined = combined.join(business[['num_establishments',"num_paid_employees", "first_quarter_payroll", "annual_payroll"]], how="inner", on="zip")
combined = combined.join(funding.drop(["idcensus","name","conum","csa","cbsa","enroll"],1), how="inner", on="math_leaid")
combined = combined.join(income.drop(["statefips",'state'], 1), how="inner", on="zip")
combined = combined.join(teachers["num_full_time"], how="inner")
combined = combined.join(title1[["title_i_status",'ntnl_school_lunch_program_status_Yes', 'title_1_eligbility__No',
       'title_1_eligbility__Not Applicable', 'title_1_eligbility__Yes',
       'school_wide_title_i_eligibility_No',
       'school_wide_title_i_eligibility_Not Applicable',
       'school_wide_title_i_eligibility_Yes',
       'ntnl_school_lunch_program_status_No',
       'ntnl_school_lunch_program_status_Yes, participating without using any Provision or the CEO',
       'ntnl_school_lunch_program_status_Yes, under Community Eligibility Option (CEO)',
       'ntnl_school_lunch_program_status_Yes, under Provision 1',
       'ntnl_school_lunch_program_status_Yes, under Provision 2']], how="inner")
combined = combined.drop(['zip'],1)
combined = combined[combined['math_all_grades_pctprof_low'] >=0]
combined = combined[combined['read_all_grades_pctprof_low'] >=0]
combined['math_full_time'] = combined['math_all_grades_numvalid']/combined['num_full_time']
combined['read_full_time'] = combined['read_all_grades_numvalid']/combined['num_full_time']

def convertStatesToNum(i):
    return mathStatesPairs[i] 
combined['stnam'] = combined['math_stnam'].apply(convertStatesToNum)
combined = combined.drop('math_stnam', 1)
len(combined)

usedFeatures = {
    'lon' : 'SCALED',
    'math_all_grades_numvalid':'SCALED_LOG',
    'lat':'SCALED',
    'pct_title1':'SCALED_LOG',
    'read_full_time':'SCALED_LOG',
    'num_full_time':'SCALED_LOG',
    'before_credits_amount':'SCALED_LOG',
    'stnam':'CAT',
    'ntnl_school_lunch_program_status_Yes, participating without using any Provision or the CEO':'NONE',
    'excess_income_credit_amount': 'SCALED_LOG',
    'num_of_head_house_returns':'SCALED_LOG',
    'pct_charges':'SCALED_LOG',
    'pct_parent_gov_cont':'SCALED',
    'pct_rev_locale':'SCALED',
    'pcts_gen_form':'SCALED',
}
def Scaler(series):
  scaler = StandardScaler()
  scaler.fit(series.values.reshape(-1,1))
  return scaler
scalers = {}

def createScalers():
    """Creates the Scalers based off the data provided"""
    for i in usedFeatures.keys():
      if usedFeatures[i] == 'SCALED':
        scalers[i] = Scaler(combined[i]) 
      elif usedFeatures[i] == 'SCALED_LOG':
        scalers[i] = Scaler(combined[i].apply(lambda x:np.log(x) if x != 0 else 0 ))

createScalers()

for i in scalers.keys():
    dump(scalers[i], 'Scalers/'+i+'.joblib')
